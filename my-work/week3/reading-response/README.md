### How do technical tools promise to "fair out" the remaining discrimination that exist in social/welfare systems? In how far can they succeed, in which ways do they fail?
By incorporating technical tools, it is claimed to take a more diverse data from more platforms and databases into considering whether a person is qualified for social/welfare aid or not. It is applicable since more information about the person is collected, which means the information could be less biased than what it is formerly do – define a person solely on the data the certain system has. And since a more comprehensive figure could be created, it is more likely that “more deserved” people would be accepted. However, with the technical tools, what is collected is still mere data, not actual person, there could be errors and one-sided information. And as what is said in the podcast, one error may lead to denial from welfare system, and such a denial may lead to a vicious circle where further misjudgment could be made. Also, such a barrier of rating people may be just excuses for welfare systems to refuse offering help due to “limited resources”.

### Imagine, what could this (following quotes) mean in the widest sense?
####	"The state doesn't need a cop to kill a person" and "electronic incarceration"
The social control is more vital to a person’s living. The instant need for shelter, nutriment, medical care and health insurance could be easily denied by the state. Neglect and abandonment kills. Such a denial doesn’t even need any excuse such as violation of law, a claim that “you are not qualified for welfare” that comes out of nowhere transparent is more threatening. So, laws are transparent, which as long as we do our parts, in most cases we are safe. But these judgements are not transparent and are easy to be manipulated by hands or interfered by “malfunctions”.

### What do you understand this to mean?
####	"systems act as a kind of 'empathy-overwrite'"
The welfare systems give moral diagnoses to people and determines who are the most deserved to be aided. It uses its own, secret criteria to judge people, and the outcome is released based solely on what the systems think. The outcome could affect people’s life, in both ways – a positive judgement leads to an even more positive consequences, while a negative one will only drag people down. People’s life is overwritten by the judgements and is affected heavily. It is just like an autocratic government, where people’s value and status are valued biasedly.

### China is much more advanced and expansive when it comes to applying technical solutions to societal processes or instant challenges. Try to point example cases in China that are in accordance or in opposition to the problematics discussed in the podcast. Perhaps you can think of
####	"technical systems not well thought-through about what their impact on human beings is"
It is said in the podcast that people are fallen into “targets” of these technology instead of “users”. It is also true for China, where cyberspace censorship has become a common term among people. Under the censorship system, there is limited things that we – the actual users of the Internet – could do. We are under the giant hands of the government and what we can do is live within the lines. Facial recognition incorporated in China’s CCTV is the most advanced around the world, and using network connection to track a person’s location and movement is not new. Such an expose to surveillance and personal tracking has been a normalcy of our life. There are certainly downsides which are obvious and we are experiencing them every day, elsewise why would we need a school VPN, or why would we always be careful of our words on the internet. But benefits are there, people are easy to track under the pervasion of the coronavirus, and a lack of personal privacy actually helps to boost the development of facial payment and mobile payment, as long as food delivery and logistics. So in my opinion, how technology should be designed really matters little, it only depends on if I am being used against or not.
